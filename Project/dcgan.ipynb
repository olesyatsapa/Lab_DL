{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d(input, output_dim=64, kernel=(5, 5), strides=(2, 2), stddev=0.2, name='conv_2d'):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable('Conv2d_W', [kernel[0], kernel[1], input.get_shape()[-1], output_dim],\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        b = tf.get_variable('Conv2d_b', [output_dim], initializer=tf.zeros_initializer())\n",
    "        \n",
    "        return tf.nn.conv2d(input, W, strides=[1, strides[0], strides[1], 1], padding='SAME') + b\n",
    "\n",
    "\n",
    "\n",
    "def Dense(input, output_dim, stddev=0.02, name='dense'):\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        shape = input.get_shape()\n",
    "        W = tf.get_variable('Dense_W', [shape[1], output_dim], tf.float32,\n",
    "                            tf.random_normal_initializer(stddev=stddev))\n",
    "        b = tf.get_variable('Dense_b', [output_dim],\n",
    "                            initializer=tf.zeros_initializer())\n",
    "        \n",
    "        return tf.matmul(input, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(X, reuse=False, name='D'):\n",
    "\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        \n",
    "        print('\\nDiscriminator vars\\n')\n",
    "        \n",
    "        \n",
    "        X_reshaped = tf.reshape(X, [-1, 28, 28, 1])\n",
    "        D_conv1 = Conv2d(X_reshaped, output_dim=64, name='d_conv1')\n",
    "        print('D_conv1', D_conv1.get_shape())\n",
    "        \n",
    "        \n",
    "        D_h1=tf.nn.leaky_relu(D_conv1)\n",
    "        print('D_h1', D_h1.get_shape())\n",
    "        \n",
    "        \n",
    "        D_conv2 = Conv2d(D_h1, output_dim=128, name='d_conv2')\n",
    "        print('D_conv2', D_conv2.get_shape())\n",
    "        \n",
    "        \n",
    "        D_h2=tf.nn.leaky_relu(D_conv2)\n",
    "        D_r2 = tf.reshape(D_h2, [-1, 256])\n",
    "        print('D_r2', D_r2.get_shape())\n",
    "        \n",
    "        \n",
    "        D_h3=tf.nn.leaky_relu(D_r2)\n",
    "        D_h4 = tf.nn.dropout(D_h3, 0.5)\n",
    "        print('D_h4', D_h4.get_shape())\n",
    "        \n",
    "        \n",
    "        D_h5 = Dense(D_h4, output_dim=1, name='d_h5') \n",
    "        print('D_h5', D_h5.get_shape())\n",
    "        \n",
    "        \n",
    "        return tf.nn.sigmoid(D_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(Z, name='G'):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        print('\\nGenerator vars\\n')\n",
    "        G_1 = Dense(Z, output_dim=1024, name='g_1') \n",
    "        print('G_1', G_1.get_shape())\n",
    "        \n",
    "        \n",
    "        G_bn1 = tf.contrib.layers.batch_norm(inputs = G_1, scale=True, scope=\"g_bn1\")\n",
    "        print('G_bn1',G_bn1.get_shape())\n",
    "        \n",
    "        \n",
    "        G_h1 = tf.nn.relu(G_bn1)\n",
    "        print('G_h1',G_h1.get_shape())\n",
    "        \n",
    "        \n",
    "        G_2 = Dense(G_h1, output_dim=7*7*128, name='g_2') # [-1, 7*7*128]\n",
    "        print('G_2',G_2.get_shape())\n",
    "        \n",
    "      \n",
    "        G_bn2 = tf.contrib.layers.batch_norm(inputs = G_2, scale=True, scope=\"g_bn2\")\n",
    "        print('G_bn2',G_bn2.get_shape())\n",
    "        \n",
    "        G_h2 = tf.nn.relu(G_bn2)\n",
    "        print('G_h2',G_h2.get_shape())\n",
    "        G_r2 = tf.reshape(G_h2, [-1, 7, 7, 128])\n",
    "        print('G_r2',G_r2.get_shape())\n",
    "        \n",
    "\n",
    "        G_conv3 = tf.layers.conv2d_transpose(G_r2, 64, (5,5), (2,2), padding='same', name='g_conv3',\n",
    "                                             activation=None, \n",
    "                                             kernel_initializer=tf.truncated_normal_initializer(stddev=0.2), \n",
    "                                             bias_initializer=tf.constant_initializer(.1))\n",
    "        print('G_conv3',G_conv3.get_shape())\n",
    "        \n",
    "        \n",
    "        G_conv3 = tf.contrib.layers.batch_norm(inputs = G_conv3, scale=True, scope=\"g_bn3\")\n",
    "        print('G_conv3',G_conv3.get_shape())\n",
    "        \n",
    "        \n",
    "        G_conv3 = tf.nn.relu(G_conv3)\n",
    "        print('G_conv3',G_conv3.get_shape())\n",
    "        \n",
    "        \n",
    "        \n",
    "        G_conv4 = tf.layers.conv2d_transpose(G_conv3, 1, (5,5), (2,2), padding='same', name='g_conv4',\n",
    "                                             activation=None, \n",
    "                                             kernel_initializer=tf.truncated_normal_initializer(stddev=0.2), \n",
    "                                             bias_initializer=tf.constant_initializer(.1))\n",
    "        \n",
    "        print('G_conv4',G_conv4.get_shape())\n",
    "        \n",
    "        \n",
    "        \n",
    "        G_r4 = tf.reshape(G_conv4, [-1, 784])\n",
    "        print('G_r4',G_r4.get_shape())\n",
    "        \n",
    "        \n",
    "        return tf.nn.sigmoid(G_r4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "Z = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "\n",
    "G = Generator(Z, 'G')\n",
    "D_loss_real = Discriminator(X, False, 'D')\n",
    "D_loss_fake = Discriminator(G, True, 'D')\n",
    "\n",
    "# discriminator loss\n",
    "D_loss = -tf.reduce_mean(tf.log(D_loss_real) - tf.log(D_loss_fake)) \n",
    "# generator loss\n",
    "G_loss = -tf.reduce_mean(tf.log(D_loss_fake)) \n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "d_vars = [v for v in tvars if v.name.startswith('D/')]\n",
    "g_vars = [v for v in tvars if v.name.startswith('G/')]\n",
    "\n",
    "optimizerD = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.1).minimize(D_loss, var_list=d_vars)\n",
    "optimizerG = tf.train.AdamOptimizer(learning_rate=2e-4, beta1=0.3).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples, D_loss, G_loss, epoch, calc_number):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))        \n",
    "\n",
    "    gs = gridspec.GridSpec(4, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    \n",
    "    # plot losses\n",
    "    ax = plt.subplot(gs[:, 4:])\n",
    "    ax.plot(D_loss, label=\"discriminator's loss\", color='b')\n",
    "    ax.plot(G_loss, label=\"generator's loss\", color='r')\n",
    "    ax.set_xlim([0, calc_number])\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.legend()\n",
    "\n",
    "    # create new images\n",
    "    for i, sample in enumerate(samples):\n",
    "        \n",
    "        # let's draw 16 pictures (4 by 4 grid). If we want more - change it\n",
    "        if i == 16:\n",
    "            break\n",
    "            \n",
    "        ax = plt.subplot(gs[i % 4, int(i / 4)])\n",
    "        plt.axis('off')\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    plt.savefig('./output_by_epochs/' + str(epoch + 1) + '.png')\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40\n",
    "#EPOCHS = 3\n",
    "D_losses = []\n",
    "G_losses = []\n",
    "iterations = int(mnist.train.images.shape[0] / BATCH_SIZE)\n",
    "# if we wanna draw plots with losses relatively the whole process-> we have to know the full number of calculations\n",
    "calc_number = EPOCHS * iterations\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        for i in range(iterations):\n",
    "            \n",
    "            x, _ = mnist.train.next_batch(BATCH_SIZE)\n",
    "            z = np.random.uniform(0.0, 1.0, size=[BATCH_SIZE, 100])\n",
    "            _, D_loss_curr = sess.run([optimizerD, D_loss], {X: x, Z: z})\n",
    "            D_losses.append(D_loss_curr)\n",
    "            \n",
    "            \n",
    "            #z = np.random.uniform(0.0, 1.0, size=[BATCH_SIZE, 100])\n",
    "            _, G_loss_curr = sess.run([optimizerG, G_loss], {Z: z})\n",
    "            G_losses.append(G_loss_curr)\n",
    "            \n",
    "            # good looking output =)\n",
    "            sys.stdout.write(\"\\r%d / %d epochs, %d / %d iterations: D_loss = %f, G_loss = %f\"\n",
    "                             %(e, EPOCHS-1, i, iterations-1, D_loss_curr, G_loss_curr))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # each epoch generate images and create an output \"set of pictures + losses\"\n",
    "        data = sess.run(G, {Z: z})\n",
    "        plot(data, D_losses, G_losses, e, calc_number) "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
